---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Zero Shot Crosslingual Eye-Tracking Data Prediction using Multilingual Transformer Models"
authors: [Harshvardhan Srivastava]
date: 2022-03-26
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: 2022-04-06T16:49:10+05:30

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["3"]

# Publication name and optional abbreviated publication name.
publication: "To Appear at *Proceedings of the 1st Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation*"
publication_short: "CMCL@ACL 2022"

abstract: "Eye tracking data during reading is a useful source of information to understand the cognitive processes that take place during language comprehension processes. Different languages account for different brain triggers , however there seems to be some uniform indicators. In this paper, we describe our submission to the CMCL 2022 shared task on predicting human reading patterns for multi-lingual dataset. Our model uses text representations from transformers and some hand engineered features with a regression layer on top to predict statistical measures of mean and standard deviation for 2 main eye-tracking features. We train an end to end model to extract meaningful information from different languages and test our model on two seperate datasets. We compare different transformer models and show ablation studies affecting model performance. Our final submission ranked 4th place for SubTask-1 and 1st place for SubTask-2 for the shared task. "

# Summary. An optional shortened abstract.
summary: "Our model uses text representations from transformers and some hand engineered features with a regression layer on top to predict statistical measures of mean and standard deviation for 2 main eye-tracking features."

tags: []
categories: []
featured: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_pdf: 
url_code: https://github.com/hvarS/CMCL-2022
url_dataset: 
url_preprint: https://arxiv.org/abs/2203.16474
url_poster: https://drive.google.com/file/d/1--_8qS1St2Z2IIME92UmbqNVq9cmwnhI/view?usp=sharing
url_project:
url_slides: https://drive.google.com/file/d/1qvnng0QQaF891ATfLsLlBhgy6PyqxDOv/view?usp=sharing
url_source:
url_video: https://drive.google.com/file/d/15g-KtHepiAvLWwwJQpC7dw6jS-WmfigM/view?usp=sharing

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: "smart"
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---
